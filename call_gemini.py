"""
call_gemini.py
---------------
M칩dulo h칤brido para integra칞칚o entre o agente EDA e LLM (Gemini / Stub).

- Se a vari치vel de ambiente GEMINI_API_KEY estiver definida, o m칩dulo usa a API real do Google Generative AI.
- Caso contr치rio, ele retorna uma resposta simulada (modo stub).

Uso:
    from call_gemini import call_gemini
    resposta = call_gemini("Explique a m칠dia de vendas por categoria")


"""

import os
import textwrap


def call_gemini(prompt: str) -> str:
    """
    Fun칞칚o h칤brida: usa Gemini se chave dispon칤vel, sen칚o retorna resposta simulada.
    """
    """
    Fun칞칚o h칤brida que usa Gemini se dispon칤vel, ou fallback stub.
    """
    api_key = os.getenv("GEMINI_API_KEY")

    if not api_key:
        # 游댳 Modo desenvolvimento (sem chave)
        return f"[Stub LLM] Resposta simulada para o prompt: {prompt[:300]}..."

    try:
        import google.generativeai as genai

        genai.configure(api_key=api_key)

        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(
            prompt,
            safety_settings={
                "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
                "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
            },
        )
        return textwrap.shorten(response.text.strip(), width=1200, placeholder="...")
    except Exception as e:
        # 游댲 Se algo falhar (ex: limite, erro de rede, timeout), ca칤mos pro stub
        return f"[Stub Fallback] Erro ao chamar LLM real: {str(e)[:150]}"
